# -*- coding: utf-8 -*-
"""
Created on Sat Jun  3 18:27:57 2023

@author: sofia2022
"""
import matplotlib.pyplot as plt


x= [100, 150, 200, 250, 300, 30, 350, 400, 450, 500, 50, 550, 600, 648]

# trained with AUC, no augmentation, larger network
y1= [0.7906131852551985, 0.8124113894139887, 0.8261164933837428, 0.824905482041588, 0.8417414933837429, 0.749734168241966, 0.849273393194707, 0.8475011814744801, 0.8376654064272212, 0.8421845463137996, 0.7427634688090737, 0.8417119565217391, 0.8534676275992439, 0.856421313799622]
# trained with accuracy, no augmentation, smaller network
y2= [0.7678698015122873, 0.769110349716446, 0.7775874291115311, 0.8156013705103969, 0.8210952268431003, 0.6042355860113422, 0.7972589792060492, 0.8166351606805293, 0.826086956521739, 0.8221880907372401, 0.6587310964083176, 0.8338551512287335, 0.7915140595463138, 0.8373995746691872]

plt.plot(x, y1, 'o', x, y2, 'x')
plt.xlabel('number of training examples')
plt.ylabel('AUC')
plt.legend(["trained with AUC","trained with Accuracy"])
plt.show()


# Accuracy
x= [100, 150, 200, 250, 300, 30, 350, 400, 450, 500, 50, 550, 600, 648]
y1= [0.6820651888847351, 0.6875, 0.70923912525177, 0.7445651888847351, 0.73097825050354, 0.510869562625885, 0.70652174949646, 0.741847813129425, 0.7554348111152649, 0.741847813129425, 0.5570651888847351, 0.7527173757553101, 0.7364130616188049, 0.7635869383811951]

y2= [0.70652174949646, 0.741847813129425, 0.7445651888847351, 0.7527173757553101, 0.7554348111152649, 0.66847825050354, 0.77173912525177, 0.7744565010070801, 0.758152186870575, 0.75, 0.679347813129425, 0.760869562625885, 0.758152186870575, 0.77173912525177]
plt.plot(x, y1, 'o', x, y2, 'x')
plt.xlabel('number of training examples')
plt.ylabel('Accuracy')
plt.legend(["trained with AUC","trained with Accuracy"])
plt.show()

#Precision
y1= [0.6401673640167364, 0.648068669527897, 0.7103825136612022, 0.7205882352941176, 0.7707006369426752, 0.5059171597633136, 0.6727272727272727, 0.7379679144385026, 0.7901234567901234, 0.7986577181208053, 0.5408560311284046, 0.7183098591549296, 0.7543859649122807, 0.7437185929648241]

y2= [0.6792452830188679, 0.7129186602870813, 0.7045454545454546, 0.743455497382199, 0.7373737373737373, 0.7313432835820896, 0.7525252525252525, 0.7853107344632768, 0.7486910994764397, 0.7169811320754716, 0.6793478260869565, 0.7424242424242424, 0.7317073170731707, 0.8164556962025317]
plt.plot(x, y1, 'o', x, y2, 'x')
plt.xlabel('number of training examples')
plt.ylabel('Precision')
plt.legend(["trained with AUC","trained with Accuracy"])
plt.show()

# Recall
y1= [0.8315217391304348, 0.8206521739130435, 0.7065217391304348, 0.7989130434782609, 0.657608695652174, 0.9293478260869565, 0.8043478260869565, 0.75, 0.6956521739130435, 0.6467391304347826, 0.7554347826086957, 0.8315217391304348, 0.7010869565217391, 0.8043478260869565]

y2= [0.782608695652174, 0.8097826086956522, 0.842391304347826, 0.7717391304347826, 0.7934782608695652, 0.532608695652174, 0.8097826086956522, 0.7554347826086957, 0.7771739130434783, 0.8260869565217391, 0.6793478260869565, 0.7989130434782609, 0.8152173913043478, 0.7010869565217391]
plt.plot(x, y1, 'o', x, y2, 'x')
plt.xlabel('number of training examples')
plt.ylabel('Recall')
plt.legend(["trained with AUC","trained with Accuracy"])
plt.show()
